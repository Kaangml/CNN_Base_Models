{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3qPWcYW2X2rP"},"outputs":[],"source":["import os\n","import json\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing import image\n","from keras.utils import to_categorical\n","from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9sLXznuSXjPU"},"outputs":[],"source":["# Google Drive Mount\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkAxOu0M7bbX"},"outputs":[],"source":["%cd '/content/drive/My Drive/Deep_Learning_homework/Data'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ovfr773cdivJ"},"outputs":[],"source":["# Veri yolları\n","csv_path = \"new_train.csv\"\n","json_path = \"label_num_to_disease_map.json\"\n","image_folder = \"train_images\"\n","# Sınıf adları\n","with open(json_path, 'r') as f:\n","    class_names = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4P6KdwhL9w_P"},"outputs":[],"source":["# Veri yollarını yükleyin\n","df = pd.read_csv(csv_path)"]},{"cell_type":"markdown","metadata":{"id":"OQI2RsT_ej10"},"source":["# **Etiket Sayısı hesaplama**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fNITh3Da0qx"},"outputs":[],"source":["# Label sütunundaki değerleri say\n","label_counts = df['label'].value_counts()\n","\n","# Etiketlerin sayısını yazdır\n","print(\"Etiket 0 olanların sayısı:\", label_counts.get(0, 0))\n","print(\"Etiket 1 olanların sayısı:\", label_counts.get(1, 0))\n","print(\"Etiket 2 olanların sayısı:\", label_counts.get(2, 0))\n","print(\"Etiket 3 olanların sayısı:\", label_counts.get(3, 0))\n","print(\"Etiket 4 olanların sayısı:\", label_counts.get(4, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0_VJlR_59kXM"},"outputs":[],"source":["# Her sınıf için resim ve labellı resim sayılarını hesapla\n","class_counts = {}\n","for label, class_name in class_names.items():\n","    class_images = len(df[df['label'] == int(label)])\n","    labeled_images = class_images\n","    class_counts[class_name] = {'images': class_images, 'labeled_images': labeled_images}\n","\n","    print(f\"Sınıf: {class_name}, Toplam Resim Sayısı: {class_images}, Etiketli Resim Sayısı: {labeled_images}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"msdEE1ormuQU"},"outputs":[],"source":["import os\n","\n","# train.csv dosyasının boyutunu yazdır\n","csv_size = os.path.getsize(csv_path)\n","print(f\"train.csv dosyasının boyutu: {csv_size} bytes\")\n","\n","# image_folder içindeki resim sayısını hesapla\n","image_files = os.listdir(image_folder)\n","num_images = len(image_files)\n","print(f\"{image_folder} klasöründe {num_images} resim bulunmaktadır.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZgtwEdzgY_C"},"outputs":[],"source":["import os\n","\n","image_folder = \"train_images\"\n","image_id = \"1000015157.jpg\"\n","\n","img_path = os.path.join(image_folder, image_id)\n","\n","if os.path.exists(img_path):\n","    print(f\"{image_id} dosyası {image_folder} klasöründe bulunuyor.\")\n","else:\n","    print(f\"{image_id} dosyası {image_folder} klasöründe bulunmuyor.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBbX8lQ4gxXx"},"outputs":[],"source":["import pandas as pd\n","\n","csv_path = \"train.csv\"\n","image_id_to_check = \"1000015157.jpg\"\n","\n","# CSV dosyasını oku\n","df = pd.read_csv(csv_path)\n","\n","# image_id sütununda belirtilen dosyanın olup olmadığını kontrol et\n","if image_id_to_check in df['image_id'].values:\n","    print(f\"{image_id_to_check} dosyası train.csv dosyasında bulunuyor.\")\n","else:\n","    print(f\"{image_id_to_check} dosyası train.csv dosyasında bulunmuyor.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cZ1-hi_BPJy"},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# Boş bir DataFrame oluştur\n","new_df = pd.DataFrame(columns=['image_id', 'label'])\n","\n","df = pd.read_csv(csv_path)\n","\n","\n","for image_id, label in zip(df['image_id'], df['label']):\n","    img_path = os.path.join(image_folder, image_id)\n","\n","    # Eğer dosya mevcutsa işleme devam et, aksi takdirde atla\n","    if os.path.exists(img_path):\n","        # Yeni bir satır oluştur\n","        new_row = pd.DataFrame({'image_id': [image_id], 'label': [label]})\n","        # Mevcut DataFrame'e yeni satırı ekle\n","        new_df = pd.concat([new_df, new_row], ignore_index=True)\n","# Sonuçları göster\n","print(new_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e95WH0pC_Of"},"outputs":[],"source":["df.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLND4XExDZVf"},"outputs":[],"source":["new_df.to_csv('new_train.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"9PiYJHJbVKJe"},"source":["# **Veri dengesizliği**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7IfEDXmV4Et"},"outputs":[],"source":["import pandas as pd\n","from sklearn.utils import resample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SpU_pkIVIdN"},"outputs":[],"source":["# Etiketlere göre veri setini bölün\n","df_class_0 = df[df['label'] == 0]\n","df_class_3 = df[df['label'] == 3]\n","\n","# Diğer sınıfları ayırın\n","df_others = df[(df['label'] != 0) & (df['label'] != 3)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MoCYxhNYVgpV"},"outputs":[],"source":["# 0 etiketli sınıfı 2000 örneğe ayarlayın\n","if len(df_class_0) < 2000:\n","    df_class_0_resampled = resample(df_class_0, replace=True, n_samples=2000, random_state=123)\n","else:\n","    df_class_0_resampled = resample(df_class_0, replace=False, n_samples=2000, random_state=123)\n","\n","# 3 etiketli sınıfı 2000 örneğe ayarlayın\n","if len(df_class_3) < 2000:\n","    df_class_3_resampled = resample(df_class_3, replace=True, n_samples=2000, random_state=123)\n","else:\n","    df_class_3_resampled = resample(df_class_3, replace=False, n_samples=2000, random_state=123)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GIoyIbnZVjZW"},"outputs":[],"source":["# Yeniden örneklenmiş veri setlerini birleştirin\n","df_resampled = pd.concat([df_class_0_resampled, df_class_3_resampled, df_others])\n","\n","# Karışık hale getirmek için verileri karıştırın\n","df_resampled = df_resampled.sample(frac=1, random_state=123).reset_index(drop=True)\n","\n","# Sonuçları kontrol edin\n","print(df_resampled['label'].value_counts())\n"]},{"cell_type":"markdown","metadata":{"id":"wKvujbzGyxJf"},"source":["resample all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LoALEaO0ywy_"},"outputs":[],"source":["import pandas as pd\n","from sklearn.utils import resample\n","\n","# Veri yolları\n","csv_path = \"new_train.csv\"\n","json_path = \"label_num_to_disease_map.json\"\n","image_folder = \"train_images\"\n","\n","# Sınıf adlarını yükleyin\n","with open(json_path, 'r') as f:\n","    class_names = json.load(f)\n","\n","# Veri setini yükleyin\n","df = pd.read_csv(csv_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PDD9cdjypPv"},"outputs":[],"source":["# Hedef örnek sayısı\n","target_count = 1000\n","\n","# Tüm sınıflar için yeniden örnekleme işlemi\n","df_resampled = pd.DataFrame()\n","\n","for label in df['label'].unique():\n","    df_class = df[df['label'] == label]\n","\n","    if len(df_class) < target_count:\n","        df_class_resampled = resample(df_class, replace=True, n_samples=target_count, random_state=123)\n","    else:\n","        df_class_resampled = resample(df_class, replace=False, n_samples=target_count, random_state=123)\n","\n","    df_resampled = pd.concat([df_resampled, df_class_resampled])\n","\n","# Karışık hale getirmek için verileri karıştırın\n","df_resampled = df_resampled.sample(frac=1, random_state=123).reset_index(drop=True)\n","\n","# Sonuçları kontrol edin\n","print(df_resampled['label'].value_counts())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzqFu-giytim"},"outputs":[],"source":["# Yeniden örneklenen veri setini kontrol edin\n","print(df_resampled.head())\n","\n","# Yeniden örneklenen veri setini kaydedin\n","df_resampled.to_csv(\"resampled_train.csv\", index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"PnIWv6Pywh9Y"},"source":["# **2**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSzf2QOuxKM6"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import json\n","from sklearn.utils import resample\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kltez0OrwhUI"},"outputs":[],"source":["# Sadece etiket 1'e ait verileri alın\n","df_class_1 = df[df['label'] == 1]\n","\n","# Etiket 1 sınıfını 2000 örneğe ayarlayın\n","df_class_1_resampled = resample(df_class_1, replace=True, n_samples=2000, random_state=123)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qkq4HgK3wtat"},"outputs":[],"source":["# Veri seti sınıfı\n","class CassavaDataset(Dataset):\n","    def __init__(self, dataframe, image_folder, transform=None):\n","        self.dataframe = dataframe\n","        self.image_folder = image_folder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.image_folder, self.dataframe.iloc[idx, 0])\n","        image = Image.open(img_name).convert('RGB')\n","        label = self.dataframe.iloc[idx, 1]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# Transformlar\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","])\n","\n","# Dataset ve DataLoader\n","dataset = CassavaDataset(dataframe=df_class_1_resampled, image_folder=image_folder, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7YGy9kJww-f"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","class Generator(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(Generator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(latent_dim, 128 * 16 * 16),\n","            nn.ReLU(True),\n","            nn.BatchNorm1d(128 * 16 * 16),\n","            nn.Unflatten(1, (128, 16, 16)),\n","            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(64),\n","            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Flatten(),\n","            nn.Linear(128 * 32 * 32, 1),  # Input shape should match the output shape of previous layers\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","latent_dim = 100\n","generator = Generator(latent_dim)\n","discriminator = Discriminator()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","generator = generator.to(device)\n","discriminator = discriminator.to(device)\n","\n","criterion = nn.BCELoss()\n","optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0L30ZYWwybH"},"outputs":[],"source":["num_epochs = 50\n","\n","for epoch in range(num_epochs):\n","    for i, (imgs, _) in enumerate(dataloader):\n","        # Gerçek görüntüler\n","        real_imgs = imgs.to(device)\n","        real_labels = torch.ones(imgs.size(0), 1).to(device)\n","        fake_labels = torch.zeros(imgs.size(0), 1).to(device)\n","\n","        # Generator için random noise\n","        z = torch.randn(imgs.size(0), latent_dim).to(device)\n","        gen_imgs = generator(z)\n","\n","        # Discriminator'ı eğit\n","        optimizer_D.zero_grad()\n","        real_loss = criterion(discriminator(real_imgs), real_labels)\n","        fake_loss = criterion(discriminator(gen_imgs.detach()), fake_labels)\n","        d_loss = real_loss + fake_loss\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        # Generator'ı eğit\n","        optimizer_G.zero_grad()\n","        g_loss = criterion(discriminator(gen_imgs), real_labels)\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} | D Loss: {d_loss.item()} | G Loss: {g_loss.item()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yN9sE41w3qA"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from torchvision.utils import save_image\n","\n","# Eğitim sonrası görüntü üretimi\n","def generate_images(generator, latent_dim, n_images=64):\n","    generator.eval()\n","    z = torch.randn(n_images, latent_dim).to(device)\n","    gen_imgs = generator(z).view(n_images, 3, 128, 128).cpu()\n","    generator.train()\n","    return gen_imgs\n","\n","# Örnek görüntü üretimi ve kaydetme\n","gen_imgs = generate_images(generator, latent_dim)\n","save_image(gen_imgs, \"generated_images.png\", nrow=8, normalize=True)\n","\n","# Görüntülerin görselleştirilmesi\n","fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n","for img, ax in zip(gen_imgs, axes.flatten()):\n","    ax.imshow(img.permute(1, 2, 0).detach().numpy() * 0.5 + 0.5)\n","    ax.axis('off')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"g4tazOdTeqeL"},"source":["# **Preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9MalpP1jZu0"},"outputs":[],"source":["import os\n","import pandas as pd\n","import cv2\n","\n","\n","# Veri ve etiket listelerini başlat\n","data = []\n","labels = []\n","success_count = 0\n","skip_count = 0\n","\n","def process_image(image_id, label):\n","    img_path = os.path.join(image_folder, image_id)\n","\n","    if os.path.exists(img_path):\n","        img = cv2.imread(img_path)\n","        if img is not None:\n","            resized_img = cv2.resize(img, (224, 224))\n","            return (resized_img, label, True)\n","    return (None, label, False)\n","\n","# Paralel işleme için ThreadPoolExecutor kullan\n","with ThreadPoolExecutor() as executor:\n","    futures = [executor.submit(process_image, image_id, label) for image_id, label in zip(df_resampled['image_id'], df_resampled['label'])]\n","\n","    for future in as_completed(futures):\n","        result, label, success = future.result()\n","        if success:\n","            data.append(result)\n","            labels.append(label)\n","            success_count += 1\n","        else:\n","            skip_count += 1\n","\n","# İşlemler tamamlandıktan sonra sonuçları yazdır\n","print(f\"Başarıyla eklenen resim sayısı: {success_count}\")\n","print(f\"Atlanan resim sayısı: {skip_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVxo5y2-jhpD"},"outputs":[],"source":["data = np.array(data)\n","labels = np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5L4FpeUR5cCQ"},"outputs":[],"source":["\n","# Data and Labels Collection\n","data = []\n","labels = []\n","success_count = 0\n","skip_count = 0\n","\n","df = pd.read_csv(\"new_train.csv\")\n","\n","for image_id, label in zip(df['image_id'], df['label']):\n","    img_path = os.path.join(image_folder, image_id)\n","\n","    # Eğer dosya mevcutsa işleme devam et, aksi takdirde atla\n","    if os.path.exists(img_path):\n","        img = cv2.imread(img_path)\n","        resized_img = cv2.resize(img, (224, 224))\n","        data.append(resized_img)\n","        labels.append(label)\n","        success_count += 1\n","    else:\n","        print(f\"Uyarı: {img_path} bulunamadı, bu nedenle atlandı.\")\n","        skip_count += 1\n","\n","# Convert to NumPy arrays\n","data = np.array(data)\n","labels = np.array(labels)\n","\n","print(f\"Başarılı işlenen fotoğraf sayısı: {success_count}\")\n","print(f\"Atlanan fotoğraf sayısı: {skip_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lVA1blW5uqe"},"outputs":[],"source":["#Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsDzGGyi5xpS"},"outputs":[],"source":["y_train = y_train.astype(int)\n","y_test = y_test.astype(int)\n","\n","num_classes = len(class_names)\n","\n","# Convert training labels to one-hot encoding\n","y_train_one_hot = to_categorical(y_train, num_classes)\n","\n","# Convert testing labels to one-hot encoding\n","y_test_one_hot = to_categorical(y_test, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mduXjFKnNRW3"},"outputs":[],"source":["y_train_one_hot.shape,y_test_one_hot.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwPsO2XjNZRc"},"outputs":[],"source":["y_train,y_test"]},{"cell_type":"markdown","metadata":{"id":"bYwIlvYNpdbB"},"source":["# **Model Oluşturma**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEqf85RXoVHA"},"outputs":[],"source":["def vggnet(input_size=(224,224,3),num_classes=5):\n","    inputs = Input(input_size)\n","\n","    # Layer 1\n","    conv1 = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(inputs)\n","    conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n","    pool1  = MaxPooling2D((2, 2))(conv2)\n","\n","    conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n","    conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n","    pool2  = MaxPooling2D((2, 2))(conv4)\n","\n","    conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n","    conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n","    conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n","    pool3  = MaxPooling2D((2, 2))(conv7)\n","\n","    conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n","    conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n","    conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n","    pool4  = MaxPooling2D((2, 2))(conv10)\n","\n","    conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n","    conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n","    conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n","    pool5  = MaxPooling2D((2, 2))(conv13)\n","\n","\n","    # Flatten\n","    flatten = Flatten()(pool5)\n","\n","    # Fully connected layers\n","    dense1 = Dense(4096, activation='relu')(flatten)\n","\n","    dense2 = Dense(4096, activation='relu')(dense1)\n","\n","    # Output layer\n","    output = Dense(num_classes, activation='softmax')(dense2)\n","\n","    model = Model(inputs=inputs, outputs=output)\n","\n","    return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pTngQdypifh"},"outputs":[],"source":["# Build vggnet Model\n","vggnet_model = vggnet(num_classes=5)\n","\n","# Print Model Summary\n","vggnet_model.summary()\n","# Compile Model\n","vggnet_model.compile(optimizer= Adam(0.01),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDEAxwVw1svj"},"outputs":[],"source":["from keras.applications import VGG16\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","\n","#Pre-trained VGG-16 modelini yükle\n","vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Yeni bir Sequential modeli oluştur\n","model = Sequential()\n","\n","# VGG-16'nın katmanlarını ekle\n","for layer in vgg16.layers:\n","    model.add(layer)\n","\n","# Yeni top layerları ekle\n","model.add(Flatten())\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(5, activation='softmax'))\n","\n","# Modeli derle\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2c6NaoXE7VI5"},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"best_vggnet_model_weights.h5\",\n","                             monitor='val_acc',  # Kaydetme kriteri olarak doğruluk metriğini kullanın\n","                             verbose=1,\n","                             save_best_only=True,    # Sadece en iyi performansı gösteren ağırlıkları kaydedin\n","                             mode='max')\n","# Callbacks\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, mode='auto', factor=0.1, min_lr=0.000001)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MP_P_ZSe7YqA"},"outputs":[],"source":["# Modeli eğit\n","history=model.fit(X_train, y_train_one_hot, epochs=100, batch_size=32, validation_split=0.2, verbose=1,callbacks=[reduce_lr,checkpoint,early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXIyXzBCjxKp"},"outputs":[],"source":["# Model Evaluation\n","evaluation = model.evaluate(X_test, y_test_one_hot)\n","test_accuracy = evaluation[1]\n","print(\"Test accuracy:\", test_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gom-Q4d5jyfB"},"outputs":[],"source":["\n","# Tahminleri yap\n","predicted_probabilities = model.predict(X_test)\n","\n","# Tahmin edilen olasılıklardan sadece pozitif sınıfın olasılıklarını seç\n","predicted_positive_probabilities = predicted_probabilities[:, 1]\n","\n","# FPR, TPR ve eşik değerlerini hesapla\n","fpr, tpr, thresholds = roc_curve(y_test_one_hot[:, 1], predicted_positive_probabilities)\n","\n","# ROC eğrisi altında alanı hesapla\n","roc_auc = auc(fpr, tpr)\n","\n","# ROC eğrisini çiz\n","plt.figure(figsize=(10, 8))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC)')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hp8t7AtUj2Hr"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","predictions = model.predict(X_test)\n","predicted_labels = np.argmax(predictions, axis=1)\n","true_labels = np.argmax(y_test_one_hot, axis=1)\n","\n","cm = confusion_matrix(true_labels, predicted_labels)\n","print(\"Confusion Matrix:\")\n","print(cm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_eK5a8lj3jz"},"outputs":[],"source":["# Grafik boyutunu ayarlayın\n","plt.figure(figsize=(20, 12))\n","# Extracting training history\n","\n","train_accuracy = history.history['accuracy']\n","val_accuracy = history.history['val_accuracy']\n","train_loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(train_accuracy) + 1)\n","\n","# Accuracy plot\n","plt.subplot(2, 2, 1)\n","plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.xticks(epochs)  # Set the x-axis ticks explicitly\n","\n","# Loss plot\n","plt.subplot(2, 2, 2)\n","plt.plot(epochs, train_loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.xticks(epochs)  # Set the x-axis ticks explicitly\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chPVBamJj401"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","predictions = model.predict(X_test)\n","\n","predicted_labels = np.argmax(predictions, axis=1)\n","\n","true_labels = np.argmax(y_test_one_hot, axis=1)\n","\n","class_report = classification_report(true_labels, predicted_labels)\n","\n","# Print the classification report\n","print(\"Classification Report:\")\n","print(class_report)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"giTq2bwjj5_a"},"outputs":[],"source":["# Karışıklık matrisini görselleştir\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 8))\n","hm = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlOrRd\", xticklabels=class_names, yticklabels=class_names)\n","hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom=False)\n","plt.xlabel('AI Prediction')\n","plt.ylabel('Actual Label')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["OQI2RsT_ej10","g4tazOdTeqeL"],"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMfQjwrJA79XY4JAwEoMZCE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}